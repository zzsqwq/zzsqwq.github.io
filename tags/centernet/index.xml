<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>CenterNet on Zs&#39;s Blog</title>
    <link>https://blog.zzsqwq.cn/tags/centernet/</link>
    <description>Recent content in CenterNet on Zs&#39;s Blog</description>
    <follow_challenge>
      <feedId>62734001391548416</feedId>
      <userId>62689941916008448</userId>
    </follow_challenge>
    <generator>Hugo -- 0.141.0</generator>
    <language>en</language>
    <lastBuildDate>Wed, 27 Jan 2021 11:50:00 +0000</lastBuildDate>
    <atom:link href="https://blog.zzsqwq.cn/tags/centernet/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>如何使用CenterNet做3D目标检测测试</title>
      <link>https://blog.zzsqwq.cn/posts/164/</link>
      <pubDate>Wed, 27 Jan 2021 11:50:00 +0000</pubDate>
      <guid>https://blog.zzsqwq.cn/posts/164/</guid>
      <description>&lt;h2 id=&#34;centernetobjects-as-points介绍&#34;&gt;CenterNet—Objects as Points介绍&lt;/h2&gt;
&lt;p&gt;​&lt;a href=&#34;https://github.com/xingyizhou/CenterNet&#34;&gt;CenterNet&lt;/a&gt;是一个anchor-free的目标检测网络，与YOLOv3相比，精度有所提升，此外他不仅能够用于2D目标检测，也能够用于人体姿态识别，3D目标检测等···&lt;/p&gt;
&lt;h3 id=&#34;安装centernet&#34;&gt;安装CenterNet&lt;/h3&gt;
&lt;p&gt;​其实安装&lt;a href=&#34;https://github.com/xingyizhou/CenterNet&#34;&gt;CenterNet&lt;/a&gt;的过程就是一个配置环境的问题，直接跟着官方给出的这里&lt;a href=&#34;https://github.com/xingyizhou/CenterNet/blob/master/readme/INSTALL.md&#34;&gt;Install.md&lt;/a&gt;配置一下即可，十分推荐使用Conda来管理环境，这里给出我的环境给大家参考一下：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Ubuntu = 18.04 LTS&lt;/p&gt;
&lt;p&gt;pytorch = 1.2.0&lt;/p&gt;
&lt;p&gt;python = 3.6.12&lt;/p&gt;
&lt;p&gt;torchvision = 0.4.0&lt;/p&gt;
&lt;p&gt;cuda = 10.2&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;​需要注意的是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;官方给出的教程里面使用的是 &lt;code&gt;pytorch 0.4.1&lt;/code&gt;，但是我个人在实测过程中遇到了一些问题，遂安装网上的教程更改为 &lt;code&gt;pytorch 1.2.0&lt;/code&gt;，并且需要把 &lt;code&gt;${CenterNet_Root}/src/lib/models/networks/DCNv2&lt;/code&gt; 中的这个&lt;a href=&#34;https://github.com/CharlesShang/DCNv2&#34;&gt;DCNv2&lt;/a&gt;网络更改为官方的最新版。&lt;/li&gt;
&lt;li&gt;这里使用的cuda版本最好和你的显卡匹配，之前因为显卡驱动的一些问题导致重装了电脑，根据我们学长学姐的建议，最好直接去cuda官网那边去下载deb包直接安装。&lt;/li&gt;
&lt;li&gt;遇到环境配置问题可以先去Google一下，一般作者都在CenterNet&amp;rsquo;s Issues中给出了回复，如果没有，可以发邮件给作者询问，当然也可以发消息/邮箱给我，大家一起探讨一下~&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;运行centernet的demo&#34;&gt;运行CenterNet的demo&lt;/h3&gt;
&lt;p&gt;​想要运行demo，首先要去 &lt;a href=&#34;https://github.com/xingyizhou/CenterNet/blob/master/readme/MODEL_ZOO.md&#34;&gt;Model zoo&lt;/a&gt; 中下载一下我们需要使用的model，2D目标检测使用的是 &lt;a href=&#34;https://drive.google.com/open?id=1pl_-ael8wERdUREEnaIfqOV_VF2bEVRT&#34;&gt;ctdet_coco_dla_2x.pth&lt;/a&gt; ，人体姿态评估使用的是 &lt;a href=&#34;https://drive.google.com/open?id=1PO1Ax_GDtjiemEmDVD7oPWwqQkUu28PI&#34;&gt;multi_pose_dla_3x.pth&lt;/a&gt; ，下载后统一将他们放在CenterNet根目录中的model文件夹中。&lt;/p&gt;
&lt;p&gt;​然后使用conda切换到CenterNet的环境，在终端中运行：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;python demo.py ctdet --demo &lt;span class=&#34;si&#34;&gt;${&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;CenterNet_Root&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;/images/17790319373_bd19b24cfc_k.jpg --load_model ../models/ctdet_coco_dla_2x.pth 
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;​这里需要注意的是 &lt;code&gt;--demo&lt;/code&gt; 后面的 &lt;code&gt;${CenterNet_Root}/images/17790319373_bd19b24cfc_k.jpg&lt;/code&gt; ，这里我使用的是官方给出的实例图片，它位于CenterNet根目录的images文件夹中，前面的 &lt;code&gt;${CenterNet_Root} &lt;/code&gt; 代表的是 CenterNet根目录，好比我的就位于 &lt;code&gt;/home/zs/CenterNet&lt;/code&gt; 。&lt;/p&gt;
&lt;p&gt;​如果不出意外的话效果应该如下图所示：&lt;/p&gt;
&lt;p&gt;&lt;img alt=&#34;2D目标检测效果&#34; loading=&#34;lazy&#34; src=&#34;https://blog.zzsqwq.cn/usr/uploads/2021/01/2469782097.jpg&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;运行centernet的3d目标检测&#34;&gt;运行CenterNet的3D目标检测&lt;/h3&gt;
&lt;h4 id=&#34;配置数据集和模型&#34;&gt;配置数据集和模型&lt;/h4&gt;
&lt;p&gt;​我们可以直接参考官方的 &lt;code&gt;DATA.md&lt;/code&gt; 来配置我们的数据集。&lt;/p&gt;
&lt;p&gt;​然后到 &lt;a href=&#34;https://github.com/xingyizhou/CenterNet/blob/master/readme/MODEL_ZOO.md&#34;&gt;Model zoo&lt;/a&gt; 下载3D检测使用的模型 &lt;a href=&#34;https://drive.google.com/open?id=1znsM6E-aVTkATreDuUVxoU0ajL1az8rz&#34;&gt;ddd_3dop.pth&lt;/a&gt; 。&lt;/p&gt;
&lt;p&gt;​这里说一下遇到的几个坑：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;首先是配置数据集的过程中，我们需要配置的目录结构如图所示（官方给出的结构树有点模糊不清的感觉）&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;.
├── ImageSets_3dop
│   ├── test.txt
│   ├── train.txt
│   ├── trainval.txt
│   └── val.txt
├── ImageSets_subcnn
│   ├── test.txt
│   ├── train.txt
│   ├── trainval.txt
│   └── val.txt
└── training
       ├── calib
       ├── image_2
       └── label_2
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;然后去到 &lt;code&gt;${CenterNet_ROOT}/src/tools&lt;/code&gt;目录下，运行 &lt;code&gt;python convert_kitti_to_coco.py &lt;/code&gt; 将 &lt;strong&gt;kitti&lt;/strong&gt; 数据集转换为 &lt;strong&gt;coco&lt;/strong&gt; 数据集的格式，不出意外应该会报错如下：&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img alt=&#34;转换时报错&#34; loading=&#34;lazy&#34; src=&#34;https://blog.zzsqwq.cn/usr/uploads/2021/01/3420056939.png&#34;&gt;&lt;/p&gt;
&lt;p&gt;这里的解决方案参考CenterNet中的一个Issue , &lt;a href=&#34;https://github.com/xingyizhou/CenterNet/issues/54&#34;&gt;How to generate the image dir in kitti?&lt;/a&gt; ，我们需要回到 &lt;code&gt;data/kitti&lt;/code&gt; 目录下手动创建一个 &lt;code&gt;annotations&lt;/code&gt; 文件夹，然后再回去运行转换程序。转换后目录结构如下：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;.
├── annotations
│   ├── kitti_3dop_train.json
│   ├── kitti_3dop_val.json
│   ├── kitti_subcnn_train.json
│   └── kitti_subcnn_val.json
├── ImageSets_3dop
│   ├── test.txt
│   ├── train.txt
│   ├── trainval.txt
│   └── val.txt
├── ImageSets_subcnn
│   ├── test.txt
│   ├── train.txt
│   ├── trainval.txt
│   └── val.txt
└── training
       ├── calib
       ├── image_2
       └── label_2
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;然后根据官方的教程，我们需要创建一个images文件夹，然后将其 &lt;code&gt;training/image_2&lt;/code&gt; 链接到 &lt;code&gt;images/trainval&lt;/code&gt;，我在实际的测试中，发现此方法并不可行。参考CenterNet中的一个Issue: &lt;a href=&#34;https://github.com/xingyizhou/CenterNet/issues/575&#34;&gt;Evaluate kitti&amp;ndash;AttributeError: &amp;lsquo;NoneType&amp;rsquo; object has no attribute &amp;lsquo;shape&amp;rsquo;&lt;/a&gt; ，其中 juanmed给出了解决方案：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;I had the same problem. For some reason the simlinks that are created during the data preparation process described in DATA.md are not working. So instead of creating simlinks I simply copied the actual data into the directories indicated in DATA.md. In other words the folders &lt;code&gt;data/kitti/images/test&lt;/code&gt; and &lt;code&gt;data/kitti/images/trainval&lt;/code&gt; do contain the actual images.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;意思就是说，我们在 &lt;strong&gt;images&lt;/strong&gt; 中的图片必须都是真实的照片，而不能只是软链接过去。&lt;/p&gt;
&lt;p&gt;解决方案很显然，只需要在 &lt;strong&gt;images&lt;/strong&gt; 文件夹中建立一个 &lt;strong&gt;trainval&lt;/strong&gt; 文件夹，将 &lt;code&gt;training/image_2&lt;/code&gt; 中的所有图像都移入其中即可。如果有test的照片，那么也照规在 &lt;strong&gt;images&lt;/strong&gt; 新建一个 &lt;strong&gt;test&lt;/strong&gt; 文件夹，把测试的照片移入其中即可。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;运行测试程序&#34;&gt;运行测试程序&lt;/h4&gt;
&lt;p&gt;接下来我们就可以根据官方给出的 &lt;a href=&#34;https://github.com/xingyizhou/CenterNet/blob/master/readme/GETTING_STARTED.md&#34;&gt;GETTING_STARTED.md&lt;/a&gt; 来进行我们的检测了。&lt;/p&gt;
&lt;p&gt;即先编译一下评估工具，然后运行测试程序，但其实还是有一点点小问题。&lt;/p&gt;
&lt;p&gt;具体问题可以参考 Issus: &lt;a href=&#34;https://github.com/xingyizhou/CenterNet/issues/55&#34;&gt;kitti test: Couldn&amp;rsquo;t read: 006042.txt of ground truth.&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Issue下 &lt;strong&gt;lhyfst&lt;/strong&gt; 已经给出了解决方案 ：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The solution is quite simple.
&lt;code&gt;cd data/kitti&lt;/code&gt;
&lt;code&gt;mv label_2 label_val&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;​    更改后，运行成功~&lt;/p&gt;
&lt;p&gt;我们应该可以在 &lt;code&gt;${CenterNet_ROOT}/exp/ddd/3dop/results&lt;/code&gt; 看到我们得到的结果，只不过运行得到的是点的坐标，而不是图像，如果需要图像的话可能还需要自己绘制一下。&lt;/p&gt;
</description>
    </item>
  </channel>
</rss>
